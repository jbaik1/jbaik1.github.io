---
title: 'Visual Perception of 3D Space and Shape in Time - Part I: 2D Space Perception
  by 2D Linear Translation'
authors:
- Umaima Afifa
- Javier Carmona
- Amy Dinh
- Diego Espino
- Trevor McCarthy
- Brian Ta
- Patrick Wilson
- Benjamin Asdell
- Jinwoo Baik
- Archana Biju
- Sonia Chung
- Christopher Dao
- Mark Diamond
- Saba Doust
- Angela East
- Diego Espino
- Kailey Fleiszig-Evans
- Adrian Franco
- Anthony Garibay-Gutierrez
- Aparajeeta Guha
- Roshan Gunturu
- Luke Handley
- Christina Honore
- Abinav Kannan
- Jared Khoo
- Mira Khosla
- Chandan Kittur
- Alexandra Kwon
- Jessica Lee
- Nicholas Lwe
- Mylan Mayer
- Elizabeth Mills
- Delilah Pineda
- Pasha Pourebrahim
- Jacob Rajacich
- Shan Rizvi
- Liliana Rosales
- Leonard Schummer
- Conor Sefkow
- Alexander Stangel
- Cindy Ta
- Ivy Ta
- Natalie Tong
- Kyle Tsujimoto
- Alyssa Vu
- Henry Wang
- Amanda Yares
- Natsuko Yamaguchi
- Ki Woong Yoon
- Shuyi Yu
- Aaron P. Blaisdell
- Katsushi Arisaka
date: '2022-01-01'
publishDate: '2024-12-06T22:54:12.480438Z'
publication_types:
- article-journal
publication: '*bioRxiv*'
doi: 10.1101/2022.03.01.482161
abstract: Visual perception plays a critical role in navigating space and extracting
  useful semantic information crucial to survival. To identify distant landmarks,
  we constantly shift gaze vectors through saccades, while still maintaining the visual
  perception of stable allocentric space. How can we sustain stable allocentric space
  so effortlessly? To solve this question, we have developed a new concept of NHT
  (Neural Holography Tomography). This model states that retinotopy is invisible (not
  available to consciousness) and must be converted to a time code by traveling alpha
  brainwaves to perceive objects consciously. According to this framework, if identical
  alpha phases are continually assigned to a landmark, we perceive its exact and consistent
  allocentric location.To test this hypothesis, we designed reaction time (RT) experiments
  to observe evidence of the predicted space-to-time conversion. Various visual stimuli
  were generated at a wide range of eccentricities either on a large TV (up to 40°)
  or by LED strips on a hemispherical dome (up to 60°). Participants were instructed
  to report the observed patterns promptly under either covert (no eye movement) or
  overt (with eye movement) conditions. As predicted, stimuli presented at the center
  of fixation always produced the fastest RTs. The additional RT delay was precisely
  proportional to the eccentricity of the peripheral stimulus presentation. Furthermore,
  both covert and overt attention protocols created the same RT delays, and trajectories
  of saccadic eye motions were in parallel to the overt RT vs. eccentricity. These
  findings strongly support our NHT model, in which the observed RT-eccentricity dependence
  is indicative of the spatiotemporal conversion required for maintaining a stable
  allocentric frame of reference. That is, we perceive space by time.Competing Interest
  StatementThe authors have declared no competing interest.
links:
- name: URL
  url: https://www.biorxiv.org/content/early/2022/03/05/2022.03.01.482161
---
